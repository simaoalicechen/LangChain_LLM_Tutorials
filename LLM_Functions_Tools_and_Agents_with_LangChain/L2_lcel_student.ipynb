{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc925562",
   "metadata": {
    "id": "fc925562"
   },
   "source": [
    "# LangChain Expression Language (LCEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "qi1tIqFRJMig",
   "metadata": {
    "id": "qi1tIqFRJMig"
   },
   "outputs": [],
   "source": [
    "# !pip install python-dotenv\n",
    "# !pip install openai\n",
    "# !pip install -U langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044db1b7-c18c-45d2-be7a-29f027c901e2",
   "metadata": {
    "height": 115,
    "id": "044db1b7-c18c-45d2-be7a-29f027c901e2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "OPENAI_API_KEY = openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "GXrvL7XjKdrN",
   "metadata": {
    "id": "GXrvL7XjKdrN"
   },
   "outputs": [],
   "source": [
    "# !pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de9d2bd-18de-44d5-81ac-5918e2106367",
   "metadata": {
    "height": 30,
    "id": "2de9d2bd-18de-44d5-81ac-5918e2106367"
   },
   "outputs": [],
   "source": [
    "# !pip install pydantic==1.10.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd55c0a0-ca4e-4311-a33c-fcebeb7d8b1e",
   "metadata": {
    "height": 64,
    "id": "fd55c0a0-ca4e-4311-a33c-fcebeb7d8b1e"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99c432b-b2c9-497b-9912-c9ca4c1e3740",
   "metadata": {
    "id": "e99c432b-b2c9-497b-9912-c9ca4c1e3740"
   },
   "source": [
    "## Simple Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a0be20d-0e00-478c-a844-017cad13af22",
   "metadata": {
    "height": 98,
    "id": "6a0be20d-0e00-478c-a844-017cad13af22"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"tell me a short joke about {topic}\"\n",
    ")\n",
    "# client = OpenAI(\n",
    "#     # This cannot be omitted\n",
    "#     api_key= OPENAI_API_KEY\n",
    "# )\n",
    "model = ChatOpenAI(api_key= OPENAI_API_KEY)\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aedf1c1e-b697-47ce-9d81-eaec9192243b",
   "metadata": {
    "height": 30,
    "id": "aedf1c1e-b697-47ce-9d81-eaec9192243b"
   },
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6df32028-d35f-4392-bb15-ddeec9ee09b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "height": 30,
    "id": "6df32028-d35f-4392-bb15-ddeec9ee09b5",
    "outputId": "b392f840-25d4-4212-ca2b-a5c82e7d2521"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Why did the bear sit on the stove? \\n\\nBecause he wanted to be a hot cross bear!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba33b5-2ae9-44d7-b023-18c903af571a",
   "metadata": {
    "id": "d8ba33b5-2ae9-44d7-b023-18c903af571a"
   },
   "source": [
    "## More complex chain\n",
    "\n",
    "And Runnable Map to supply user-provided inputs to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d036bb8e-8ca7-4dbd-8103-f50a3c8c3af9",
   "metadata": {
    "height": 47,
    "id": "d036bb8e-8ca7-4dbd-8103-f50a3c8c3af9"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "kuH80JxgLLFI",
   "metadata": {
    "id": "kuH80JxgLLFI"
   },
   "outputs": [],
   "source": [
    "# !pip install docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8955cff7-f1a2-4f94-ab5b-fcdda0859702",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 98,
    "id": "8955cff7-f1a2-4f94-ab5b-fcdda0859702",
    "outputId": "47ee8b1d-6abb-412f-faf7-b444fba4096a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "    embedding=OpenAIEmbeddings(api_key= OPENAI_API_KEY)\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2df87934-1697-405c-b460-5e9bfd16c792",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "2df87934-1697-405c-b460-5e9bfd16c792",
    "outputId": "09562da1-37a5-4608-f508-a335e2a91e45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-265df7017aee>:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retriever.get_relevant_documents(\"where did harrison work?\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='harrison worked at kensho'),\n",
       " Document(metadata={}, page_content='bears like to eat honey')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"where did harrison work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "871cb26b-97b3-4f63-8bb3-523d3e6d117b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "871cb26b-97b3-4f63-8bb3-523d3e6d117b",
    "outputId": "57212eeb-f137-4006-cf76-e33b74b68e19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='bears like to eat honey'),\n",
       " Document(metadata={}, page_content='harrison worked at kensho')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"what do bears like to eat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "127a7fb6-5821-4934-ab56-9e3300516c05",
   "metadata": {
    "height": 115,
    "id": "127a7fb6-5821-4934-ab56-9e3300516c05"
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kgp-lr9oRy9o",
   "metadata": {
    "id": "Kgp-lr9oRy9o"
   },
   "source": [
    "we want the first input to be the user question.\n",
    "\n",
    "We then want context, and then pass into prompt, then model, and get an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ec01c56-731c-4e4f-a5f6-493fba953db0",
   "metadata": {
    "height": 30,
    "id": "4ec01c56-731c-4e4f-a5f6-493fba953db0"
   },
   "outputs": [],
   "source": [
    "# runnable map is one way\n",
    "from langchain.schema.runnable import RunnableMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9ca6506-826f-4420-8f19-25dd4dbbc1dc",
   "metadata": {
    "height": 81,
    "id": "a9ca6506-826f-4420-8f19-25dd4dbbc1dc"
   },
   "outputs": [],
   "source": [
    "# create a runnable object\n",
    "chain = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),  # call the retriever\n",
    "    \"question\": lambda x: x[\"question\"] # using another lambda\n",
    "}) | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "707d1319-8840-4ed5-b4a4-a2a128799db6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "height": 30,
    "id": "707d1319-8840-4ed5-b4a4-a2a128799db6",
    "outputId": "7d41306e-056a-48c9-eb6a-53db5cb5cc67"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Harrison worked at Kensho.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only one response, which is the correct one.\n",
    "chain.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05ec3727-4284-417e-9e23-eec0682eb002",
   "metadata": {
    "height": 81,
    "id": "05ec3727-4284-417e-9e23-eec0682eb002"
   },
   "outputs": [],
   "source": [
    "# get context and questions.\n",
    "# get prompt, model, and then return the chat message. (string)\n",
    "inputs = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4216c7ab-6d1b-4f2a-98dc-5d2ace23e3c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "4216c7ab-6d1b-4f2a-98dc-5d2ace23e3c2",
    "outputId": "b17bf0c8-12f3-45f7-ea69-a789156346fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(metadata={}, page_content='harrison worked at kensho'),\n",
       "  Document(metadata={}, page_content='bears like to eat honey')],\n",
       " 'question': 'where did harrison work?'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec59c3b-33e7-437f-9b8b-b4652bc3b863",
   "metadata": {
    "id": "eec59c3b-33e7-437f-9b8b-b4652bc3b863"
   },
   "source": [
    "## Bind\n",
    "\n",
    "and OpenAI Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5YYkESrSSYki",
   "metadata": {
    "id": "5YYkESrSSYki"
   },
   "source": [
    "The idea is a prompt, and a model. And then the function.\n",
    "\n",
    "When the model is called, parameters are binded and then function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oNI0ay6VSYKJ",
   "metadata": {
    "id": "oNI0ay6VSYKJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "PQAalH4HRcG_",
   "metadata": {
    "id": "PQAalH4HRcG_"
   },
   "outputs": [],
   "source": [
    "# need new syntex\n",
    "\n",
    "# bind parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3efed3b-6d4c-42a4-9692-0cc4596f530b",
   "metadata": {
    "height": 285,
    "id": "f3efed3b-6d4c-42a4-9692-0cc4596f530b"
   },
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"airport_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The airport code to get the weather for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"airport_code\"]\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ISdGbNQ8PILS",
   "metadata": {
    "id": "ISdGbNQ8PILS"
   },
   "outputs": [],
   "source": [
    "# prompt = openai.chat.completions.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"Write out the following equation using algebraic symbols then solve it. Use the format\\n\\nEQUATION:...\\nSOLUTION:...\\n\\n\",\n",
    "#         ),\n",
    "#         (\"human\", \"{equation_statement}\"),\n",
    "#     ]\n",
    "# )\n",
    "# model = ChatOpenAI(temperature=0)\n",
    "# runnable = (\n",
    "#     {\"equation_statement\": RunnablePassthrough()} | prompt | model | StrOutputParser()\n",
    "# )\n",
    "\n",
    "# print(runnable.invoke(\"x raised to the third plus seven equals 12\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8be4721-91d2-4ae6-8fdb-e91dc6ac1bc5",
   "metadata": {
    "height": 115,
    "id": "f8be4721-91d2-4ae6-8fdb-e91dc6ac1bc5"
   },
   "outputs": [],
   "source": [
    "# prompt = openai.chat.completions.create(\n",
    "#     [\n",
    "#         (\"human\", \"{input}\")\n",
    "#     ]\n",
    "# )\n",
    "# model = ChatOpenAI(temperature=0).bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e61b095d-9934-41b8-a794-a9dd57e9c733",
   "metadata": {
    "height": 30,
    "id": "e61b095d-9934-41b8-a794-a9dd57e9c733"
   },
   "outputs": [],
   "source": [
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a638efeb-b5ce-4aa4-8377-3e86597a03ab",
   "metadata": {
    "height": 30,
    "id": "a638efeb-b5ce-4aa4-8377-3e86597a03ab"
   },
   "outputs": [],
   "source": [
    "runnable.invoke({\"input\": \"what is the weather in sf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22faf5-ea24-48d2-b028-03733b548225",
   "metadata": {
    "height": 523,
    "id": "3a22faf5-ea24-48d2-b028-03733b548225"
   },
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"airport_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The airport code to get the weather for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"airport_code\"]\n",
    "      }\n",
    "    },\n",
    "        {\n",
    "      \"name\": \"sports_search\",\n",
    "      \"description\": \"Search for news of recent sport events\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"team_name\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The sports team to search for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"team_name\"]\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43b030-459f-47e8-a27d-96c2d70cdfef",
   "metadata": {
    "height": 30,
    "id": "eb43b030-459f-47e8-a27d-96c2d70cdfef"
   },
   "outputs": [],
   "source": [
    "model = model.bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff03e0d-d6c6-4b47-815e-d7ea5b248567",
   "metadata": {
    "height": 30,
    "id": "3ff03e0d-d6c6-4b47-815e-d7ea5b248567"
   },
   "outputs": [],
   "source": [
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03855fa3-5e2f-4ab2-aba0-c2cd5423239e",
   "metadata": {
    "height": 30,
    "id": "03855fa3-5e2f-4ab2-aba0-c2cd5423239e"
   },
   "outputs": [],
   "source": [
    "runnable.invoke({\"input\": \"how did the patriots do yesterday?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc0c55-48c2-4105-90ec-7297553b8e6a",
   "metadata": {
    "id": "bebc0c55-48c2-4105-90ec-7297553b8e6a"
   },
   "source": [
    "## Fallbacks\n",
    "### (this is actuallly from an older model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B2yyQviRS6u-",
   "metadata": {
    "id": "B2yyQviRS6u-"
   },
   "source": [
    "# not only individual componehts, but entire sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lk3a6qCGS6Oz",
   "metadata": {
    "id": "lk3a6qCGS6Oz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa0b1ea2-7aef-4449-a553-426cb8c5aa30",
   "metadata": {
    "height": 47,
    "id": "aa0b1ea2-7aef-4449-a553-426cb8c5aa30"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef73d77-9cac-419a-9583-8aefc6c9277b",
   "metadata": {
    "id": "bef73d77-9cac-419a-9583-8aefc6c9277b"
   },
   "source": [
    "**Note**: Due to the deprecation of OpenAI's model `text-davinci-001` on 4 January 2024, you'll be using OpenAI's recommended replacement model `gpt-3.5-turbo-instruct` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "df432efe-9415-42e3-ab57-ecf4d439f369",
   "metadata": {
    "height": 115,
    "id": "df432efe-9415-42e3-ab57-ecf4d439f369"
   },
   "outputs": [],
   "source": [
    "simple_model = OpenAI(\n",
    "    api_key= OPENAI_API_KEY,\n",
    "    # temperature=0,\n",
    "    # max_tokens=1000,\n",
    "    model=\"gpt-3.5-turbo-instruct\"\n",
    "    # model = \"text-davinci-001\" # old\n",
    ")\n",
    "simple_chain = simple_model | json.loads\n",
    "\n",
    "# the result would not be json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "441928c5-8712-45c5-bfdf-6f51634198a7",
   "metadata": {
    "height": 30,
    "id": "441928c5-8712-45c5-bfdf-6f51634198a7"
   },
   "outputs": [],
   "source": [
    "challenge = \"write three poems in a json blob, where each poem is a json blob of a title, author, and first line\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "NwjfteLcVqTo",
   "metadata": {
    "id": "NwjfteLcVqTo"
   },
   "outputs": [],
   "source": [
    "challenge2 = \"write a short story of 100 words in english. be as creative and realistic as possible. A story about everyday life. write this story in a json blob\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "A-J-MpkYWPqf",
   "metadata": {
    "id": "A-J-MpkYWPqf"
   },
   "outputs": [],
   "source": [
    "challenge3 = \"give me a list of gracery list and a short explaination why I need each item. Write in json format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0739e85f-8497-4471-8ec9-17e958d80771",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "height": 30,
    "id": "0739e85f-8497-4471-8ec9-17e958d80771",
    "outputId": "1fe183ce-0a2d-4da9-8d53-5ee52589bfba"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n\\n{\\n  \"title\": \"The Sun and the Moon\",\\n  \"author\": \"Emily Smith\",\\n  \"first_line\": \"The sun and the moon, they dance in the sky\"\\n}\\n\\n{\\n  \"title\": \"Autumn Leaves\",\\n  \"author\": \"Michael Johnson\",\\n  \"first_line\": \"Golden leaves falling from the trees\"\\n}\\n\\n{\\n  \"title\": \"A New Day\",\\n  \"author\": \"Sarah Lee\",\\n  \"first_line\": \"As the sun rises, a new day begins\" \\n}'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "sF5R5jRcVzWl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "sF5R5jRcVzWl",
    "outputId": "3ff2a75a-f3a0-4f9c-dd0d-0dbd789bd36d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n\\n{\\n  \"title\": \"A Day in the Life\",\\n  \"characters\": [\"Emma\", \"Mark\"],\\n  \"setting\": \"Suburban neighborhood\",\\n  \"mainEvent\": \"Emma and Mark\\'s daily routine\",\\n  \"mood\": \"content\",\\n  \"story\": \"Emma and Mark woke up to the sound of their alarm clock at 6am. They went for their morning jog around their suburban neighborhood, enjoying the fresh air and each other\\'s company. After their run, they had a quick breakfast before heading off to work. Emma worked at a law firm while Mark was a teacher. Despite their busy schedules, they always made time for a lunch date at their favorite cafe. After work, they went grocery shopping and cooked dinner together. As they snuggled on the couch, watching their favorite show, Emma thought to herself, \\'This is our everyday life, and I wouldn\\'t want it any other way.\\'\" \\n}'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.invoke(challenge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "YWjqF33NWah9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "YWjqF33NWah9",
    "outputId": "b59b3498-5339-4ed0-e66c-75fdc89bc5d3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n\\n\\n{\\n  \"Grocery List\": [\\n    {\\n      \"Item\": \"Milk\",\\n      \"Explanation\": \"Milk is a good source of calcium and essential for strong bones and teeth.\"\\n    },\\n    {\\n      \"Item\": \"Eggs\",\\n      \"Explanation\": \"Eggs are a versatile and protein-rich ingredient that can be used for various dishes.\"\\n    },\\n    {\\n      \"Item\": \"Bread\",\\n      \"Explanation\": \"Bread is a staple food and can be used for making sandwiches, toast, and various other dishes.\"\\n    },\\n    {\\n      \"Item\": \"Fresh Vegetables\",\\n      \"Explanation\": \"Fresh vegetables are a good source of vitamins and minerals and are essential for a balanced diet.\"\\n    },\\n    {\\n      \"Item\": \"Fresh Fruits\",\\n      \"Explanation\": \"Fresh fruits are a good source of antioxidants and essential for a healthy immune system.\"\\n    },\\n    {\\n      \"Item\": \"Meat\",\\n      \"Explanation\": \"Meat is a good source of protein and iron and can be used for various dishes.\"\\n    },\\n    {\\n      \"Item\": \"Pasta\",\\n      \"Explanation\": \"Pasta is a versatile and easy-to-cook ingredient that can be used for making various dishes'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.invoke(challenge3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a20d15c-dc8a-4b6d-a423-a5f814425219",
   "metadata": {
    "id": "3a20d15c-dc8a-4b6d-a423-a5f814425219"
   },
   "source": [
    "**Note**: The next line is expected to fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a5e8492-0927-4a3a-b939-947826246330",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "height": 30,
    "id": "2a5e8492-0927-4a3a-b939-947826246330",
    "outputId": "4b53362e-045d-4083-f676-b59c00d43c0c"
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 3 column 2 (char 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-7b2363c45b31>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimple_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchallenge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3022\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3023\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4704\u001b[0m         \"\"\"\n\u001b[1;32m   4705\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4706\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m   4707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4708\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1921\u001b[0m             output = cast(\n\u001b[1;32m   1922\u001b[0m                 \u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 context.run(\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4560\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4562\u001b[0;31m             output = call_func_with_variable_args(\n\u001b[0m\u001b[1;32m   4563\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4564\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extra data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 3 column 2 (char 3)"
     ]
    }
   ],
   "source": [
    "simple_chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6814143b-4a35-4d29-bd32-ba461274bcbf",
   "metadata": {
    "height": 47,
    "id": "6814143b-4a35-4d29-bd32-ba461274bcbf"
   },
   "outputs": [],
   "source": [
    "model = ChatOpenAI(api_key= OPENAI_API_KEY)\n",
    "chain = model | StrOutputParser() | json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f55f04cf-0217-4106-b41f-0e0661d12c27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "f55f04cf-0217-4106-b41f-0e0661d12c27",
    "outputId": "7379cc17-9cc1-4173-c752-ba9dc6a8cd10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poem1': {'title': 'The Rose',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'first_line': 'A rose by any other name would smell as sweet.'},\n",
       " 'poem2': {'title': 'The Road Not Taken',\n",
       "  'author': 'Robert Frost',\n",
       "  'first_line': 'Two roads diverged in a yellow wood,'},\n",
       " 'poem3': {'title': 'I Wandered Lonely as a Cloud',\n",
       "  'author': 'William Wordsworth',\n",
       "  'first_line': 'I wandered lonely as a cloud'}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(challenge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "lSLW6macV9Cq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lSLW6macV9Cq",
    "outputId": "291ad803-7ca1-4176-ad98-b76f7abdd2fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'The Daily Commute',\n",
       " 'word_count': 100,\n",
       " 'story': 'Every morning, Sarah rushed to catch the crowded bus to work. She squeezed in next to a man in a suit and a woman with a crying baby. The bus jolted and swayed as it made its way through traffic. Sarah checked her phone, scrolling through emails and notifications. As the bus neared her stop, she gathered her things and stood up, ready to face another day at the office. She smiled at the familiar faces around her, knowing they were all in the same boat. The daily grind may be tiring, but it brought a sense of camaraderie.'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(challenge2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "AZNSb0nYWdnN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZNSb0nYWdnN",
    "outputId": "38a1f5aa-3869-45d5-af29-9a7a31895917"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grocery_list': {'eggs': 'to use for baking and cooking recipes',\n",
       "  'milk': 'for drinking and as an ingredient in various recipes',\n",
       "  'bread': 'for making sandwiches and toast',\n",
       "  'chicken': 'to cook for meals throughout the week',\n",
       "  'vegetables': 'to incorporate into meals for added nutrition',\n",
       "  'fruits': 'for snacking and adding to dishes for a natural sweetness',\n",
       "  'rice': 'to use as a side dish or base for meals',\n",
       "  'pasta': 'for making quick and easy meals',\n",
       "  'cereal': 'for breakfast or a quick snack',\n",
       "  'cheese': 'for adding flavor to dishes or as a snack on its own'}}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(challenge3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b5d3f035-b18d-4cba-854d-a43ef8554e48",
   "metadata": {
    "height": 30,
    "id": "b5d3f035-b18d-4cba-854d-a43ef8554e48"
   },
   "outputs": [],
   "source": [
    "final_chain = simple_chain.with_fallbacks([chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9a09fe6a-548c-412d-9468-9efe2b49f7c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "9a09fe6a-548c-412d-9468-9efe2b49f7c9",
    "outputId": "6803c247-2937-440a-c321-05ee58234a9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poem1': {'title': 'The Rose',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'A rose by any other name would smell as sweet.'},\n",
       " 'poem2': {'title': 'The Road Not Taken',\n",
       "  'author': 'Robert Frost',\n",
       "  'firstLine': 'Two roads diverged in a yellow wood,'},\n",
       " 'poem3': {'title': 'Hope is the Thing with Feathers',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'Hope is the thing with feathers'}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6AzAwgYxWM7h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6AzAwgYxWM7h",
    "outputId": "a4597088-d16e-4749-83bb-18cc596a8171"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'story': \"Every morning, Sarah would wake up to the sound of her alarm clock blaring. She would groggily make her way to the kitchen, brewing a strong cup of coffee to kickstart her day. As she sat at her desk, she would tackle her never-ending to-do list, checking off tasks one by one. In the afternoon, she would take a break and go for a walk in the park, enjoying the fresh air and sunshine. In the evening, she would cook a simple dinner and relax on the couch with a good book. This was Sarah's routine, but she found comfort in its familiarity.\"}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(challenge2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "m4_2ymTHWg3p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4_2ymTHWg3p",
    "outputId": "9b34b179-a4c1-4277-9e4c-46b7f627bdcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grocery_list': [{'item': 'eggs',\n",
       "   'reason': 'a versatile ingredient used in many recipes for breakfast, baking, and cooking'},\n",
       "  {'item': 'milk',\n",
       "   'reason': 'a staple for making beverages, baking, and cooking'},\n",
       "  {'item': 'bread',\n",
       "   'reason': 'a quick and easy option for making sandwiches or toast'},\n",
       "  {'item': 'chicken', 'reason': 'a lean protein source for preparing meals'},\n",
       "  {'item': 'vegetables',\n",
       "   'reason': 'essential for a balanced diet and adding nutrients to meals'},\n",
       "  {'item': 'fruits',\n",
       "   'reason': 'a healthy snack option and source of vitamins and minerals'},\n",
       "  {'item': 'rice',\n",
       "   'reason': 'a versatile staple for making side dishes or main courses'},\n",
       "  {'item': 'pasta',\n",
       "   'reason': 'a quick and easy option for making a variety of dishes'},\n",
       "  {'item': 'cereal',\n",
       "   'reason': 'a convenient breakfast option for a quick and filling meal'},\n",
       "  {'item': 'snacks',\n",
       "   'reason': 'to have on hand for quick and satisfying munchies'}]}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(challenge3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcfdda0-3db2-4073-a647-f2d62c460349",
   "metadata": {
    "id": "3fcfdda0-3db2-4073-a647-f2d62c460349"
   },
   "source": [
    "## Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33b3b27f-b5a0-4db5-a1b0-20754437a47e",
   "metadata": {
    "height": 132,
    "id": "33b3b27f-b5a0-4db5-a1b0-20754437a47e"
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a short joke about {topic}\"\n",
    ")\n",
    "model = ChatOpenAI(api_key= OPENAI_API_KEY)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "NWcC3pDyVKCa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "NWcC3pDyVKCa",
    "outputId": "091262d6-ffe4-4e47-8dc3-ed70e175b897"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Why did the tomato turn red? Because it saw the salad dressing!'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"food\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "kheDw_KsVSO6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kheDw_KsVSO6",
    "outputId": "4f30bce9-7c40-45e9-99ec-a9118a088c5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why did the bear bring a backpack to the picnic? \\n\\nIn case he wanted to go for a bear hike!',\n",
       " 'Why did the tomato turn red? Because it saw the salad dressing!']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"food\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "_5pyi8V9VdlD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_5pyi8V9VdlD",
    "outputId": "7b96820b-da8c-4200-e64f-4ca3bf22bf96"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Why did the tomato turn red? Because it saw the salad dressing!'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await chain.ainvoke({\"topic\": \"food\"})\n",
    "response\n",
    "\n",
    "# one thing at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "G2s4HmW5VbP8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "G2s4HmW5VbP8",
    "outputId": "2fba2896-ed7f-4715-c2c9-a93558452e9d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Why don't bears wear shoes? \\nBecause they have bear feet!\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await chain.ainvoke({\"topic\": \"bears\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48c8cabf-ea55-4448-b070-3ec22942c559",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "height": 30,
    "id": "48c8cabf-ea55-4448-b070-3ec22942c559",
    "outputId": "4413b355-0348-4923-8129-cec1dadef4d9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Why did the bear break up with his girlfriend? \\n\\nBecause he couldn't bear the relationship any longer!\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc58bdb4-a896-46ba-90c4-1b333245229a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "cc58bdb4-a896-46ba-90c4-1b333245229a",
    "outputId": "b616579e-d83b-4592-884a-2ee52d8883d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Why did the bear break up with the circus?\\n\\nBecause he couldn't bear being in a cage anymore!\",\n",
       " 'Why did the frog take the bus to work? Because his car got toad away!']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"frogs\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8a069d61-0a67-4368-b7c4-367262267bb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "8a069d61-0a67-4368-b7c4-367262267bb8",
    "outputId": "ac251aea-f438-4bdc-9335-6d4d3a9bf2e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why\n",
      " do\n",
      " bears\n",
      " have\n",
      " hairy\n",
      " coats\n",
      "?\n",
      "\n",
      "F\n",
      "ur\n",
      " protection\n",
      "!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2315b43f-c7e1-4f7b-9595-4cabdc019dea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "height": 47,
    "id": "2315b43f-c7e1-4f7b-9595-4cabdc019dea",
    "outputId": "5daa6310-acbd-4a08-f592-2d940b36d9f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Why did the bear bring a flashlight to the party? \\nBecause he heard it was going to be a \"beary\" good time!'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await chain.ainvoke({\"topic\": \"bears\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe48ff0-fd84-4c9e-8069-02117d57f7f0",
   "metadata": {
    "height": 30,
    "id": "5fe48ff0-fd84-4c9e-8069-02117d57f7f0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3df44d6-62d0-4324-8052-419503a6b040",
   "metadata": {
    "id": "a3df44d6-62d0-4324-8052-419503a6b040"
   },
   "source": [
    "# OpenAI Function Calling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b038f2-759a-42e9-ab02-eca264b93ee5",
   "metadata": {
    "id": "59b038f2-759a-42e9-ab02-eca264b93ee5"
   },
   "source": [
    "**Notes**:\n",
    "- LLM's don't always produce the same results. The results you see in this notebook may differ from the results you see in the video.\n",
    "- Notebooks results are temporary. Download the notebooks to your local machine if you wish to save your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ijJZRK7mycTg",
   "metadata": {
    "id": "ijJZRK7mycTg"
   },
   "source": [
    "## outline (for this course)\n",
    "\n",
    "- OpenAi function calling\n",
    "- LangChain Expression Language (LCEL)\n",
    "- OpenAI function calling in LangChain\n",
    "- Tagging and extraction using OpenAI function calling\n",
    "- Tools and Routing\n",
    "- Conversational Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sbIhbwdMzCHA",
   "metadata": {
    "id": "sbIhbwdMzCHA"
   },
   "source": [
    "## Function calling\n",
    "\n",
    "- OpenAI has fine-tuned the gpt-3.5 turbo-0613 and gpt-4-0613 models to :\n",
    "  1. accept additional arguments through which users can pass in descriptions of functions.\n",
    "  2. if it is relevant, return the nam of the function to use, along with a JSON object with teh appropriate input parameters.\n",
    "\n",
    "\n",
    "#### did not really follow the tutorials, as the syntex are basically completely different\n",
    "\n",
    "#### base codes: https://platform.openai.com/docs/guides/function-calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "G2PLvLoRtPvi",
   "metadata": {
    "id": "G2PLvLoRtPvi"
   },
   "outputs": [],
   "source": [
    "# !pip install python-dotenv\n",
    "# !pip install openai\n",
    "# !pip install -U langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3d1a7aac-599c-4653-b497-49fe9a31a07d",
   "metadata": {
    "height": 115,
    "id": "3d1a7aac-599c-4653-b497-49fe9a31a07d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "LANGCHAIN_API_KEY = os.environ['LANGCHAIN_API_KEY']\n",
    "OPENAI_API_KEY = openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e036b435-e842-40a3-8e1c-1d5d716394c6",
   "metadata": {
    "height": 234,
    "id": "e036b435-e842-40a3-8e1c-1d5d716394c6"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "290fae11-d9af-40f8-9b78-3d6a847737b2",
   "metadata": {
    "height": 319,
    "id": "290fae11-d9af-40f8-9b78-3d6a847737b2"
   },
   "outputs": [],
   "source": [
    "# define a function\n",
    "\n",
    "# functions = [\n",
    "#     {\n",
    "#         \"name\": \"get_current_weather\",\n",
    "#         \"description\": \"Get the current weather in a given location\",\n",
    "#         \"parameters\": {\n",
    "#             \"type\": \"object\",\n",
    "#             \"properties\": {\n",
    "#                 \"location\": {\n",
    "#                     \"type\": \"string\",\n",
    "#                     \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "#                 },\n",
    "#                 \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "#             },\n",
    "#             \"required\": [\"location\"],\n",
    "#         },\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# new syntex requires insert function into part of the tools\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\":  {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5b5e2abe-7cf0-4b00-8c08-b3df91d78eaa",
   "metadata": {
    "height": 115,
    "id": "5b5e2abe-7cf0-4b00-8c08-b3df91d78eaa"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Boston?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "654fce05-7ef6-49d7-8d78-f190ecf3f0dd",
   "metadata": {
    "height": 30,
    "id": "654fce05-7ef6-49d7-8d78-f190ecf3f0dd"
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "44LkB4tHvkP9",
   "metadata": {
    "id": "44LkB4tHvkP9"
   },
   "outputs": [],
   "source": [
    "# an example of new syntex from: https://github.com/openai/openai-python\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key= OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bqsJ0SrOwqRK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqsJ0SrOwqRK",
    "outputId": "a231b212-d66f-41a4-d699-30f34ac49c94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-A9dVGD7BkBfTP67XXyKSXpYCk0dFx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This is a test.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1726860166, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=5, prompt_tokens=12, total_tokens=17, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "jsBN5XGv16nu",
   "metadata": {
    "id": "jsBN5XGv16nu"
   },
   "outputs": [],
   "source": [
    "# tools = [\n",
    "#     {\n",
    "#         \"type\": \"function\",\n",
    "#         \"function\": {\n",
    "#             \"name\": \"get_current_weather\",\n",
    "#             \"description\": \"Get the current weather in a given location\",\n",
    "#             \"parameters\": {\n",
    "#                 \"type\": \"object\",\n",
    "#                 \"properties\": {\n",
    "#                 \"location\": {\n",
    "#                     \"type\": \"string\",\n",
    "#                     \"description\": \"Boston\",\n",
    "#                 },\n",
    "#                 },\n",
    "#                 \"required\": [\"order_id\"],\n",
    "#                 \"additionalProperties\": False,\n",
    "#             },\n",
    "#         }\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful assistant and will answer any user's questions.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Hi, can you tell me the weather in Boston?\"}\n",
    "# ]\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_delivery_date\",\n",
    "            \"description\": \"Get the delivery date for a customer's order. Call this whenever you need to know the delivery date, for example when a customer asks 'Where is my package'\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"order_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The customer's order ID.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"order_id\"],\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful customer support assistant. Use the supplied tools to assist the user.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi, what is the weather like in Boston?\"}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    # functions = functions,\n",
    "    # function_call=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aZk9BcAL18Dg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZk9BcAL18Dg",
    "outputId": "70812fb5-05d3-42a9-f2ca-5216ba273496"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-A9dVHpdlpkr7N8ZCld1BZUI58DpL2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I don't have the capability to provide real-time weather updates. You can check a weather website or use a weather application for the most current information. If you need help with an order or delivery, feel free to ask!\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1726860167, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=45, prompt_tokens=104, total_tokens=149, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ffa6385a-db38-40fa-b2b8-6fa226913c46",
   "metadata": {
    "height": 98,
    "id": "ffa6385a-db38-40fa-b2b8-6fa226913c46"
   },
   "outputs": [],
   "source": [
    "# response = openai.ChatCompletion.create(\n",
    "#     model=\"gpt-3.5-turbo-0613\",\n",
    "#     messages=messages,\n",
    "#     functions=functions\n",
    "# )\n",
    "# import OpenAI\n",
    "\n",
    "# source: https://platform.openai.com/docs/guides/chat-completions/getting-started\n",
    "# https://platform.openai.com/docs/api-reference/chat/streaming\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    api_key= OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "# response1 = client.chat.completions.create(\n",
    "#   model=\"gpt-4o-mini\",\n",
    "#   messages=[\n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "#     {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "#   ]\n",
    "# )\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages= messages,\n",
    "  # new syntex\n",
    "  tools=tools,\n",
    "  # function_call=\"auto\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# messages = [\n",
    "#     {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": \"What's the weather like in Boston?\"\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "\n",
    "# from openai import OpenAI\n",
    "\n",
    "# response = client.chat.completions.create(\n",
    "#     # model=\"gpt-4o-mini\",\n",
    "#     messages=messages,\n",
    "#     functions=functions,\n",
    "#     model=\"gpt-3.5-turbo-1106\",\n",
    "#     # response_format={\"type\": \"json_object\"}\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ntn1LhWZ4GFT",
   "metadata": {
    "id": "ntn1LhWZ4GFT"
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_delivery_date\",\n",
    "            \"description\": \"Get the delivery date for a customer's order. Call this whenever you need to know the delivery date, for example when a customer asks 'Where is my package'\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"order_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The customer's order ID.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"order_id\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"You are a helpful customer support assistant. Use the supplied tools to assist the user.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Hi, can you tell me the delivery date for my order?\"})\n",
    "# // highlight-start\n",
    "messages.append({\"role\": \"assistant\", \"content\": \"Hi there! I can help with that. Can you please provide your order ID?\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"i think it is order_12345\"})\n",
    "# // highlight-end\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "Es6m7mCF4TRK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Es6m7mCF4TRK",
    "outputId": "540d2153-d81b-490b-e959-8085970365b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-A9dVJ4o6IXZ4wX6KQtYH4AbgnLPai', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Your order with ID **order_12345** is scheduled to be delivered on **September 20, 2024**. If you have any other questions or need further assistance, feel free to ask!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1726860169, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=42, prompt_tokens=131, total_tokens=173, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "# Simulate the order_id and delivery_date\n",
    "from datetime import datetime\n",
    "order_id = \"order_12345\"\n",
    "delivery_date = datetime.now()\n",
    "\n",
    "# Simulate the tool call response\n",
    "response = {\n",
    "    \"choices\": [\n",
    "        {\n",
    "            \"message\": {\n",
    "                \"role\": \"assistant\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"call_62136354\",\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": {\n",
    "                            \"arguments\": \"{'order_id': 'order_12345'}\",\n",
    "                            \"name\": \"get_delivery_date\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a message containing the result of the function call\n",
    "function_call_result_message = {\n",
    "    \"role\": \"tool\",\n",
    "    \"content\": json.dumps({\n",
    "        \"order_id\": order_id,\n",
    "        \"delivery_date\": delivery_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }),\n",
    "    \"tool_call_id\": response['choices'][0]['message']['tool_calls'][0]['id']\n",
    "}\n",
    "\n",
    "# Prepare the chat completion call payload\n",
    "completion_payload = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful customer support assistant. Use the supplied tools to assist the user.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hi, can you tell me the delivery date for my order?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Hi there! I can help with that. Can you please provide your order ID?\"},\n",
    "        {\"role\": \"user\", \"content\": \"i think it is order_12345\"},\n",
    "        response['choices'][0]['message'],\n",
    "        function_call_result_message\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Call the OpenAI API's chat completions endpoint to send the tool call result back to the model\n",
    "response = openai.chat.completions.create(\n",
    "    model=completion_payload[\"model\"],\n",
    "    messages=completion_payload[\"messages\"]\n",
    ")\n",
    "\n",
    "# Print the response from the API. In this case it will typically contain a message such as \"The delivery date for your order #12345 is xyz. Is there anything else I can help you with?\"\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "xjtrPbIS4cfv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xjtrPbIS4cfv",
    "outputId": "195b366c-a6c2-41c7-9f12-1923edd948a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-A9dVJ4o6IXZ4wX6KQtYH4AbgnLPai', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Your order with ID **order_12345** is scheduled to be delivered on **September 20, 2024**. If you have any other questions or need further assistance, feel free to ask!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1726860169, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=42, prompt_tokens=131, total_tokens=173, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dEZAaJsExCvN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dEZAaJsExCvN",
    "outputId": "cc88b13c-7c3f-416f-845a-e2fc37057baa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-A9cvyKJ47MV0cIw5fvFeT6ZLtfC4w\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"function_call\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": null,\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"location\\\":\\\"Boston, MA\\\"}\",\n",
      "                    \"name\": \"get_current_weather\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1726857978,\n",
      "    \"model\": \"gpt-3.5-turbo-1106\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": null,\n",
      "    \"system_fingerprint\": \"fp_e81b59fe66\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 17,\n",
      "        \"prompt_tokens\": 82,\n",
      "        \"total_tokens\": 99\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "class FunctionCall:\n",
    "    def __init__(self, arguments, name):\n",
    "        self.arguments = arguments\n",
    "        self.name = name\n",
    "\n",
    "class ChatCompletionMessage:\n",
    "    def __init__(self, content, refusal, role, function_call):\n",
    "        self.content = content\n",
    "        self.refusal = refusal\n",
    "        self.role = role\n",
    "        self.function_call = function_call\n",
    "\n",
    "class Choice:\n",
    "    def __init__(self, finish_reason, index, logprobs, message):\n",
    "        self.finish_reason = finish_reason\n",
    "        self.index = index\n",
    "        self.logprobs = logprobs\n",
    "        self.message = message\n",
    "\n",
    "class ChatCompletion:\n",
    "    def __init__(self, id, choices, created, model, object, service_tier, system_fingerprint, usage):\n",
    "        self.id = id\n",
    "        self.choices = choices\n",
    "        self.created = created\n",
    "        self.model = model\n",
    "        self.object = object\n",
    "        self.service_tier = service_tier\n",
    "        self.system_fingerprint = system_fingerprint\n",
    "        self.usage = usage\n",
    "\n",
    "function_call = FunctionCall(arguments='{\"location\":\"Boston, MA\"}', name=\"get_current_weather\")\n",
    "message = ChatCompletionMessage(content=None, refusal=None, role=\"assistant\", function_call=function_call)\n",
    "choice = Choice(finish_reason=\"function_call\", index=0, logprobs=None, message=message)\n",
    "chat_completion = ChatCompletion(id=\"chatcmpl-A9cvyKJ47MV0cIw5fvFeT6ZLtfC4w\", choices=[choice], created=1726857978,\n",
    "                                model=\"gpt-3.5-turbo-1106\", object=\"chat.completion\", service_tier=None,\n",
    "                                system_fingerprint=\"fp_e81b59fe66\", usage={\"completion_tokens\": 17, \"prompt_tokens\": 82, \"total_tokens\": 99})\n",
    "\n",
    "# Now manually converting the ChatCompletion object to a serializable dictionary\n",
    "chat_completion_dict = {\n",
    "    \"id\": chat_completion.id,\n",
    "    \"choices\": [\n",
    "        {\n",
    "            \"finish_reason\": choice.finish_reason,\n",
    "            \"index\": choice.index,\n",
    "            \"logprobs\": choice.logprobs,\n",
    "            \"message\": {\n",
    "                \"content\": choice.message.content,\n",
    "                \"refusal\": choice.message.refusal,\n",
    "                \"role\": choice.message.role,\n",
    "                \"function_call\": {\n",
    "                    \"arguments\": choice.message.function_call.arguments,\n",
    "                    \"name\": choice.message.function_call.name\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"created\": chat_completion.created,\n",
    "    \"model\": chat_completion.model,\n",
    "    \"object\": chat_completion.object,\n",
    "    \"service_tier\": chat_completion.service_tier,\n",
    "    \"system_fingerprint\": chat_completion.system_fingerprint,\n",
    "    \"usage\": chat_completion.usage\n",
    "}\n",
    "\n",
    "# Now use json.dumps to prettify the response\n",
    "pretty_response = json.dumps(chat_completion_dict, indent=4)\n",
    "print(pretty_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "qOQGCkUy3uIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOQGCkUy3uIA",
    "outputId": "2ac45ac4-af0d-4a15-8098-6db43fa77490"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-A9dVJ4o6IXZ4wX6KQtYH4AbgnLPai', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Your order with ID **order_12345** is scheduled to be delivered on **September 20, 2024**. If you have any other questions or need further assistance, feel free to ask!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1726860169, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=42, prompt_tokens=131, total_tokens=173, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5748f7ce-9c74-435f-b5dc-d04e627675e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "5748f7ce-9c74-435f-b5dc-d04e627675e3",
    "outputId": "b8de1d0d-f288-493e-802d-2b0ba68b6c3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Your order with ID **order_12345** is scheduled to be delivered on **September 20, 2024**. If you have any other questions or need further assistance, feel free to ask!', refusal=None, role='assistant', function_call=None, tool_calls=None))]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_message = response.choices\n",
    "response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "eea5a420-9c52-441c-b868-6ce69c498477",
   "metadata": {
    "height": 30,
    "id": "eea5a420-9c52-441c-b868-6ce69c498477"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1ab51675-a078-4704-b63b-9f722d86b0d9",
   "metadata": {
    "height": 30,
    "id": "1ab51675-a078-4704-b63b-9f722d86b0d9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0d4c2a24-c011-4c44-a78e-611143ff3034",
   "metadata": {
    "height": 30,
    "id": "0d4c2a24-c011-4c44-a78e-611143ff3034"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "600778a5-a4d5-44aa-b3a7-172c82e74eed",
   "metadata": {
    "height": 30,
    "id": "600778a5-a4d5-44aa-b3a7-172c82e74eed"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "60557042-93b5-4172-8aaa-1219ea35addb",
   "metadata": {
    "height": 30,
    "id": "60557042-93b5-4172-8aaa-1219ea35addb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "693f24b4-0796-4c2d-86ab-0d23766551d3",
   "metadata": {
    "height": 30,
    "id": "693f24b4-0796-4c2d-86ab-0d23766551d3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "611029f7-e4c5-45b0-bcc9-9ec214a32686",
   "metadata": {
    "height": 30,
    "id": "611029f7-e4c5-45b0-bcc9-9ec214a32686"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e20ed315-b80a-4d82-bda8-41cc54b30b36",
   "metadata": {
    "height": 30,
    "id": "e20ed315-b80a-4d82-bda8-41cc54b30b36"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "be374e72-c849-4962-bb50-33607824bab1",
   "metadata": {
    "height": 30,
    "id": "be374e72-c849-4962-bb50-33607824bab1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9a7702f2-cee6-4649-a662-6d1dc9d49e0c",
   "metadata": {
    "height": 30,
    "id": "9a7702f2-cee6-4649-a662-6d1dc9d49e0c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "37a2ba14-9908-48b1-adad-1ef764114254",
   "metadata": {
    "height": 30,
    "id": "37a2ba14-9908-48b1-adad-1ef764114254"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

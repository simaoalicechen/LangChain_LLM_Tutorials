{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81456dd",
   "metadata": {
    "id": "a81456dd"
   },
   "source": [
    "# Lesson 1: Multi-Agent Conversation and Stand-up Comedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4693467e",
   "metadata": {
    "id": "4693467e"
   },
   "source": [
    "Welcome to Lesson 1.\n",
    "\n",
    "To access the `requirements.txt` file and the`utils` modules, please go to the `File` menu and select`Open...`.\n",
    "\n",
    "I hope you enjoy this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742cf649",
   "metadata": {
    "id": "742cf649"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "HU1ekZcFHtCz",
   "metadata": {
    "id": "HU1ekZcFHtCz"
   },
   "outputs": [],
   "source": [
    "# # !pip install openai\n",
    "# !pip install autogen\n",
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04d006c1-22fa-40ea-b3e0-d543142e0788",
   "metadata": {
    "height": 64,
    "id": "04d006c1-22fa-40ea-b3e0-d543142e0788"
   },
   "outputs": [],
   "source": [
    "from utils_ import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()\n",
    "llm_config = {\"model\": \"gpt-3.5-turbo\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a1c4d",
   "metadata": {
    "id": "116a1c4d"
   },
   "source": [
    "## Define an AutoGen agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pnrqHEiPJAfm",
   "metadata": {
    "id": "pnrqHEiPJAfm"
   },
   "outputs": [],
   "source": [
    "# reset all those keys\n",
    "import os\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fb8c441-c58c-41a8-a54b-5c387afceac5",
   "metadata": {
    "height": 132,
    "id": "6fb8c441-c58c-41a8-a54b-5c387afceac5"
   },
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    # api_key = OPENAI_API_KEY,\n",
    "    name=\"chatbot\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47886b5f-fc7c-431a-8036-cff6e88f85c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 81,
    "id": "47886b5f-fc7c-431a-8036-cff6e88f85c6",
    "outputId": "fc5172e9-bdfa-41f6-d3a4-cc3736558e53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a joke for you: Why don't scientists trust atoms? Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67f626e9-4cec-40c1-abde-2eff1252b848",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 96,
    "id": "67f626e9-4cec-40c1-abde-2eff1252b848",
    "outputId": "168dde82-c1bb-42d9-f9f9-25b052703c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I'd be happy to! Just let me know which joke you'd like me to repeat.\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Repeat the joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)\n",
    "# no memory\n",
    "# new state\n",
    "# so use multiple agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c98a301",
   "metadata": {
    "id": "8c98a301"
   },
   "source": [
    "## Conversation\n",
    "\n",
    "Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f109dcb-824e-40d7-8e86-efee42b75f3c",
   "metadata": {
    "height": 300,
    "id": "8f109dcb-824e-40d7-8e86-efee42b75f3c"
   },
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"Start the next joke from the punchline of the previous joke.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# set up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f71a61",
   "metadata": {
    "id": "43f71a61"
   },
   "source": [
    "**Note**: You might get a slightly different response (set of jokes) than what is shown in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46a1c6f6-687e-40de-8819-374201cfed9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 98,
    "id": "46a1c6f6-687e-40de-8819-374201cfed9f",
    "outputId": "7659cad6-f1cb-48b7-be23-8f96e2835abe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joe (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Hey Joe! Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Haha, Cathy! Speaking of awards, I recently won the procrastination award. It was supposed to be given to me last year, but I finally got it last month.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "That's hilarious, Joe! Sounds like you truly earned that award with impeccable timing. Remember, why put off for tomorrow what you can put off for the day after tomorrow, right?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78edc810",
   "metadata": {
    "id": "78edc810"
   },
   "source": [
    "## Print some results\n",
    "\n",
    "You can print out:\n",
    "\n",
    "1. Chat history\n",
    "2. Cost\n",
    "3. Summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1169ea24-eadd-4909-8d56-9b7ec5677c66",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 64,
    "id": "1169ea24-eadd-4909-8d56-9b7ec5677c66",
    "outputId": "6f60dd5c-1909-4a95-dd3d-bd99f320ee49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': \"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
      "  'name': 'joe',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'Hey Joe! Why did the scarecrow win an award? Because he was '\n",
      "             'outstanding in his field!',\n",
      "  'name': 'cathy',\n",
      "  'role': 'user'},\n",
      " {'content': 'Haha, Cathy! Speaking of awards, I recently won the '\n",
      "             'procrastination award. It was supposed to be given to me last '\n",
      "             'year, but I finally got it last month.',\n",
      "  'name': 'joe',\n",
      "  'role': 'assistant'},\n",
      " {'content': \"That's hilarious, Joe! Sounds like you truly earned that award \"\n",
      "             'with impeccable timing. Remember, why put off for tomorrow what '\n",
      "             'you can put off for the day after tomorrow, right?',\n",
      "  'name': 'cathy',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "550267b6-3652-40dc-9997-c5401f6d4c47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "550267b6-3652-40dc-9997-c5401f6d4c47",
    "outputId": "46da7c0b-0144-417e-8787-d1e0b804f159"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_excluding_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 93,\n",
      "                                                             'cost': 0.00025,\n",
      "                                                             'prompt_tokens': 221,\n",
      "                                                             'total_tokens': 314},\n",
      "                                      'total_cost': 0.00025},\n",
      " 'usage_including_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 93,\n",
      "                                                             'cost': 0.00025,\n",
      "                                                             'prompt_tokens': 221,\n",
      "                                                             'total_tokens': 314},\n",
      "                                      'total_cost': 0.00025}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.cost)\n",
    "# tokens ... cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfcf468e-d217-4731-8cb4-3485377230f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "dfcf468e-d217-4731-8cb4-3485377230f1",
    "outputId": "b6e755b2-d25e-472a-d9a8-14780a123037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"That's hilarious, Joe! Sounds like you truly earned that award with \"\n",
      " 'impeccable timing. Remember, why put off for tomorrow what you can put off '\n",
      " 'for the day after tomorrow, right?')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8c6cf8",
   "metadata": {
    "id": "ba8c6cf8"
   },
   "source": [
    "## Get a better summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1a8fef1-8030-4652-a2d2-1648834f62c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 132,
    "id": "c1a8fef1-8030-4652-a2d2-1648834f62c2",
    "outputId": "b2d2e187-f357-4d75-c53e-812301e4d8bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joe (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Hey Joe! Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Haha, Cathy! Speaking of awards, I recently won the procrastination award. It was supposed to be given to me last year, but I finally got it last month.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "That's hilarious, Joe! Sounds like you truly earned that award with impeccable timing. Remember, why put off for tomorrow what you can put off for the day after tomorrow, right?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
    "    max_turns=2,\n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b042de62-bc49-49ee-99f2-4f972e23670b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "b042de62-bc49-49ee-99f2-4f972e23670b",
    "outputId": "26575c6f-6d6a-416d-d23a-37399b6e4ebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Joe and Cathy exchanged jokes about winning awards, poking fun at '\n",
      " 'procrastination and timing.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300525bd",
   "metadata": {
    "id": "300525bd"
   },
   "source": [
    "## Chat Termination\n",
    "\n",
    "Chat can be terminated using a termination conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "044dfd61-7f1d-46d8-9e28-4b2601b43d70",
   "metadata": {
    "height": 351,
    "id": "044dfd61-7f1d-46d8-9e28-4b2601b43d70"
   },
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc49d959-1025-4709-8866-9d4035eaeae7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 81,
    "id": "bc49d959-1025-4709-8866-9d4035eaeae7",
    "outputId": "48590e0f-3600-4a9a-a82a-c3fe12a726ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joe (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Hey Joe, glad you're up for some laughs. Alright, here's one for you: Why did the tomato turn red? Because it saw the salad dressing!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Haha, that's a classic one, Cathy! Here's one for you: Why don't scientists trust atoms? Because they make up everything!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Haha, that's a good one, Joe! Science jokes are always electron... I mean, electrifying!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Haha, nice one, Cathy! You really know how to spark some laughter!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Haha, thanks Joe! Gotta keep the comedic fire burning!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Haha, absolutely! Keep that fire roaring, Cathy! If you ever need more material, I've got plenty of jokes up my sleeve.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Thanks, Joe! I might just take you up on that offer. It's always great to have a joke in the holster. You never know when you'll need it!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "That's the spirit, Cathy! Always be prepared for some comedic relief. I gotta go. Keep the laughter alive!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "846eccbd-efd1-464b-9385-279c19b17c1d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 45,
    "id": "846eccbd-efd1-464b-9385-279c19b17c1d",
    "outputId": "8b21ed86-db85-4cbd-8388-0696e0215aee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cathy (to joe):\n",
      "\n",
      "What's last joke we talked about?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "The last joke we talked about was your pun about keeping the comedic fire burning! It was quite electrifying!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "That's right! Thanks for the reminder. Take care, Joe! Keep those jokes coming!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Thanks, Cathy! You take care too. Remember, laughter is the best medicine! See you next time!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "I gotta go\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cathy.send(message=\"What's last joke we talked about?\", recipient=joe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4J9ViX04OHh7",
   "metadata": {
    "id": "4J9ViX04OHh7"
   },
   "outputs": [],
   "source": [
    "# basically, the point is, as long as you set a termination phrase\n",
    "# the two agents will keep chat until they run into the\n",
    "# termination phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3QTacO2PG8u",
   "metadata": {
    "id": "f3QTacO2PG8u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

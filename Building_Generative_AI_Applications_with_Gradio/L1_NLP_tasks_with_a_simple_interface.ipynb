{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88535ead",
   "metadata": {
    "id": "88535ead"
   },
   "source": [
    "# L1: NLP tasks with a simple interface üóûÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faa43ba",
   "metadata": {
    "id": "6faa43ba"
   },
   "source": [
    "Load your HF API key and relevant Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o5xy-BvGLdYg",
   "metadata": {
    "id": "o5xy-BvGLdYg"
   },
   "source": [
    "## mostly, using 1) summarization (facebook/bart-large-cnn), 2) text entity detection (dslim/bert-base-NER) tools (hf models) to summarize and identify entity and use UI tools to interact with people.\n",
    "\n",
    "## did not use the gradio UI part for dslim/bert-base-NER, as did not use the AWS endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lgEyCKAxEh7T",
   "metadata": {
    "id": "lgEyCKAxEh7T"
   },
   "source": [
    "# Small specialist model\n",
    "\n",
    "- Designed for a specific task\n",
    "- Similar performance as a general purpose LLM\n",
    "- Cheaper and faster to run compared to a general purpose LLM\n",
    "\n",
    "\n",
    "- Summarize text and name them to recommendation  \n",
    "\n",
    "## mainly using facebook bart-large-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B4H0FCmOHUEx",
   "metadata": {
    "id": "B4H0FCmOHUEx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caOiN-i_FWy1",
   "metadata": {
    "id": "caOiN-i_FWy1"
   },
   "outputs": [],
   "source": [
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2698081-4deb-436a-a821-8ea48bdd6e6a",
   "metadata": {
    "height": 149,
    "id": "d2698081-4deb-436a-a821-8ea48bdd6e6a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from IPython.display import Image, display, HTML\n",
    "from PIL import Image\n",
    "import base64\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']\n",
    "# hf_api_key = hf_api_key\n",
    "hf_api_summary_base = 'https://api-inference.huggingface.co/models/facebook/bart-large-cnn'\n",
    "# 'https://api-inference.huggingface.co/models/dslim/bert-base-NER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a106ab02-f248-4c03-9dd8-b1991db7f778",
   "metadata": {
    "height": 317,
    "id": "a106ab02-f248-4c03-9dd8-b1991db7f778"
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "import requests, json\n",
    "\n",
    "#Summarization endpoint\n",
    "def get_completion(inputs, parameters=None,ENDPOINT_URL=hf_api_summary_base):\n",
    "    headers = {\n",
    "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = { \"inputs\": inputs }\n",
    "    if parameters is not None:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    response = requests.request(\"POST\",\n",
    "                                ENDPOINT_URL, headers=headers,\n",
    "                                data=json.dumps(data)\n",
    "                               )\n",
    "    return json.loads(response.content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01892d1a",
   "metadata": {
    "id": "01892d1a"
   },
   "source": [
    "### How about running it locally?\n",
    "The code would look very similar if you were running it locally instead of from an API. The same is true for all the models in the rest of the course, make sure to check the [Pipelines](https://huggingface.co/docs/transformers/main_classes/pipelines) documentation page\n",
    "\n",
    "```py\n",
    "from transformers import pipeline\n",
    "\n",
    "get_completion = pipeline(\"summarization\", model=\"shleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "def summarize(input):\n",
    "    output = get_completion(input)\n",
    "    return output[0]['summary_text']\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97a06f9",
   "metadata": {
    "id": "a97a06f9"
   },
   "source": [
    "## Building a text summarization app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2f0fc58-91d6-48f2-a014-052192586be8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 266,
    "id": "c2f0fc58-91d6-48f2-a014-052192586be8",
    "outputId": "d7d484ff-9bd1-4eff-80c3-71e688a18aab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building. Its base is square, measuring 125 metres (410 ft) on each side. It is the second tallest free-standing structure in France after the Millau Viaduct.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ('''The tower is 324 metres (1,063 ft) tall, about the same height\n",
    "        as an 81-storey building, and the tallest structure in Paris.\n",
    "        Its base is square, measuring 125 metres (410 ft) on each side.\n",
    "        During its construction, the Eiffel Tower surpassed the Washington\n",
    "        Monument to become the tallest man-made structure in the world,\n",
    "        a title it held for 41 years until the Chrysler Building\n",
    "        in New York City was finished in 1930. It was the first structure\n",
    "        to reach a height of 300 metres. Due to the addition of a broadcasting\n",
    "        aerial at the top of the tower in 1957, it is now taller than the\n",
    "        Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the\n",
    "        Eiffel Tower is the second tallest free-standing structure in France\n",
    "        after the Millau Viaduct.''')\n",
    "\n",
    "get_completion(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144593f",
   "metadata": {
    "id": "f144593f"
   },
   "source": [
    "### Getting started with Gradio `gr.Interface`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40o4q-LlHfG_",
   "metadata": {
    "id": "40o4q-LlHfG_"
   },
   "outputs": [],
   "source": [
    "# !pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eb11460",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "height": 164,
    "id": "3eb11460",
    "outputId": "7fa96994-99be-478c-f914-d995ee23da6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://b4200338f0b9768688.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://b4200338f0b9768688.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def summarize(input):\n",
    "    output = get_completion(input)\n",
    "    return output[0]['summary_text']\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=summarize, inputs=\"text\", outputs=\"text\")\n",
    "demo.launch(share=True, server_port=int(8070))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b310770",
   "metadata": {
    "id": "9b310770"
   },
   "source": [
    "`demo.launch(share=True)` lets you create a public link to share with your team or friends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60684b55-c7ae-4c9e-88ea-bbc2e702ecdb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "height": 266,
    "id": "60684b55-c7ae-4c9e-88ea-bbc2e702ecdb",
    "outputId": "872200c0-a5fc-4271-e64f-62ccc9fa4497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 8060\n",
      "Closing server running on port: 8070\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://2148a4215ce5c232a8.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2148a4215ce5c232a8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def summarize(input):\n",
    "    output = get_completion(input)\n",
    "    return output[0]['summary_text']\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=summarize,\n",
    "                    inputs=[gr.Textbox(label=\"Text to summarize\", lines=6)],\n",
    "                    outputs=[gr.Textbox(label=\"Result\", lines=3)],\n",
    "                    # you can modify how long the summary would be, here lines = 3\n",
    "                    title=\"Text summarization with distilbart-cnn\",\n",
    "                    description=\"Summarize any text using the `shleifer/distilbart-cnn-12-6` model under the hood!\"\n",
    "                   )\n",
    "demo.launch(share=True, server_port=int(8060))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CWlq6dJmL_ep",
   "metadata": {
    "id": "CWlq6dJmL_ep"
   },
   "source": [
    "# Bert Model\n",
    "\n",
    "### Bert is a Machine Learning model for natural language processing.\n",
    "### When parsing a text, it is useful to identify specific entities such as persons, companies, places, etc.\n",
    "### To do so, we are using bert-base-NER, a 108 M parameter fine-tuned BERT model taht is ready to use for Named Entity Recognition (NER)\n",
    "## Bert-base-NER has been trained to recognize four types of entities: localtion (LOC), organizations (ORG), person(PER), and Miscellaneous (MISC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b300d17",
   "metadata": {
    "id": "4b300d17"
   },
   "source": [
    "## Building a Named Entity Recognition app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1043f",
   "metadata": {
    "id": "c0d1043f"
   },
   "source": [
    "We are using this [Inference Endpoint](https://huggingface.co/inference-endpoints) for `dslim/bert-base-NER`, a 108M parameter fine-tuned BART model on the NER task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f663dcbb",
   "metadata": {
    "id": "f663dcbb"
   },
   "source": [
    "### How about running it locally?\n",
    "\n",
    "```py\n",
    "from transformers import pipeline\n",
    "\n",
    "get_completion = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
    "\n",
    "def ner(input):\n",
    "    output = get_completion(input)\n",
    "    return {\"text\": input, \"entities\": output}\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "CP1XsWZxQOVe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "CP1XsWZxQOVe",
    "outputId": "1042f962-8ea2-4240-8ce3-c73046ad49d6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://api-inference.huggingface.co/models/facebook/bart-large-cnn'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_api_summary_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "VuW_n751Q723",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VuW_n751Q723",
    "outputId": "8c773bd8-fbae-4d04-e5a2-c469457551d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-PER', 'score': 0.9990139, 'index': 4, 'word': 'Wolfgang', 'start': 11, 'end': 19}, {'entity': 'B-LOC', 'score': 0.999645, 'index': 9, 'word': 'Berlin', 'start': 34, 'end': 40}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "text = \"My name is Wolfgang and I live in Berlin\"\n",
    "\n",
    "ner_results = nlp(text)\n",
    "print(ner_results)\n",
    "\n",
    "# object detection in sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "Lr4y4dq3PaoR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lr4y4dq3PaoR",
    "outputId": "9b88b6ad-209e-4773-ec95-e1098ff9c6e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"end\": 4,\n",
      "        \"entity\": \"B-PER\",\n",
      "        \"index\": 1,\n",
      "        \"score\": 0.9985072016716003,\n",
      "        \"start\": 0,\n",
      "        \"word\": \"Wolf\"\n",
      "    },\n",
      "    {\n",
      "        \"end\": 7,\n",
      "        \"entity\": \"I-PER\",\n",
      "        \"index\": 2,\n",
      "        \"score\": 0.8715917468070984,\n",
      "        \"start\": 4,\n",
      "        \"word\": \"##gan\"\n",
      "    },\n",
      "    {\n",
      "        \"end\": 26,\n",
      "        \"entity\": \"B-LOC\",\n",
      "        \"index\": 6,\n",
      "        \"score\": 0.9993138313293457,\n",
      "        \"start\": 20,\n",
      "        \"word\": \"Berlin\"\n",
      "    },\n",
      "    {\n",
      "        \"end\": 83,\n",
      "        \"entity\": \"B-MISC\",\n",
      "        \"index\": 16,\n",
      "        \"score\": 0.9977426528930664,\n",
      "        \"start\": 74,\n",
      "        \"word\": \"Classical\"\n",
      "    },\n",
      "    {\n",
      "        \"end\": 183,\n",
      "        \"entity\": \"B-MISC\",\n",
      "        \"index\": 35,\n",
      "        \"score\": 0.9996920824050903,\n",
      "        \"start\": 176,\n",
      "        \"word\": \"Western\"\n",
      "    },\n",
      "    {\n",
      "        \"end\": 349,\n",
      "        \"entity\": \"B-PER\",\n",
      "        \"index\": 68,\n",
      "        \"score\": 0.997958779335022,\n",
      "        \"start\": 343,\n",
      "        \"word\": \"Mozart\"\n",
      "    },\n",
      "    {\n",
      "        \"end\": 427,\n",
      "        \"entity\": \"B-MISC\",\n",
      "        \"index\": 82,\n",
      "        \"score\": 0.9996808767318726,\n",
      "        \"start\": 420,\n",
      "        \"word\": \"Western\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# make it neat format\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "text = \"Wolfgan was born in Berlin. He was a prolific and influential composer of Classical period. \\\n",
    "He had a short life, but composed more than 800 works, representing virtually every Western classical genre of his time. \\\n",
    "Many of these compositions are acknowledged as pinnacles of the symphonic, concertante, chamber, operatic, and choral repertoire. \\\n",
    "Mozart is widely regarded as one of the greatest composers in the history of Western music,with his music admired for its \\\n",
    "'melodic beauty, its formal elegance and its richness of harmony and texture'.\"\n",
    "\n",
    "ner_results = nlp(text)\n",
    "\n",
    "# change float32 values to Python native floats for JSON serialization, important\n",
    "for result in ner_results:\n",
    "    result['score'] = float(result['score'])\n",
    "\n",
    "# neat format\n",
    "json_format= json.dumps(ner_results, indent=4, sort_keys=True)\n",
    "print(json_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "rOmoXdJWSm5U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOmoXdJWSm5U",
    "outputId": "27e37ea6-258c-4d0c-ad8c-e9442efdb6e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"end\": 4,\n",
      "        \"entity\": \"B-PER\",\n",
      "        \"index\": 1,\n",
      "        \"score\": 0.9987508058547974,\n",
      "        \"start\": 0,\n",
      "        \"word\": \"Wolf\"\n",
      "    },\n",
      "    {\n",
      "        \"end\": 7,\n",
      "        \"entity\": \"I-PER\",\n",
      "        \"index\": 2,\n",
      "        \"score\": 0.8392647504806519,\n",
      "        \"start\": 4,\n",
      "        \"word\": \"##gan\"\n",
      "    },\n",
      "    {\n",
      "        \"end\": 26,\n",
      "        \"entity\": \"B-LOC\",\n",
      "        \"index\": 6,\n",
      "        \"score\": 0.9993405938148499,\n",
      "        \"start\": 20,\n",
      "        \"word\": \"Berlin\"\n",
      "    },\n",
      "    {\n",
      "        \"end\": 86,\n",
      "        \"entity\": \"B-PER\",\n",
      "        \"index\": 20,\n",
      "        \"score\": 0.9987033605575562,\n",
      "        \"start\": 80,\n",
      "        \"word\": \"Mozart\"\n",
      "    },\n",
      "    {\n",
      "        \"end\": 157,\n",
      "        \"entity\": \"B-MISC\",\n",
      "        \"index\": 33,\n",
      "        \"score\": 0.9995831847190857,\n",
      "        \"start\": 150,\n",
      "        \"word\": \"Western\"\n",
      "    },\n",
      "    {\n",
      "        \"end\": 182,\n",
      "        \"entity\": \"B-LOC\",\n",
      "        \"index\": 38,\n",
      "        \"score\": 0.9995728135108948,\n",
      "        \"start\": 176,\n",
      "        \"word\": \"Vienna\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# make it neat format\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "text = \"Wolfgan was born in Berlin. He was a composer. \\\n",
    "He composed more than 800 works. \\\n",
    "Mozart is regarded as one of the greatest composers in the history of Western music. \\\n",
    "He visited Vienna in 1781.\"\n",
    "\n",
    "ner_results = nlp(text)\n",
    "\n",
    "# change float32 values to Python native floats for JSON serialization, important\n",
    "for result in ner_results:\n",
    "    result['score'] = float(result['score'])\n",
    "\n",
    "# neat format\n",
    "json_format= json.dumps(ner_results, indent=4, sort_keys=True)\n",
    "print(json_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0db4a922-b300-4dbc-8768-955b6a18dce4",
   "metadata": {
    "height": 79,
    "id": "0db4a922-b300-4dbc-8768-955b6a18dce4"
   },
   "outputs": [],
   "source": [
    "# not in use\n",
    "# # API_URL = os.environ['HF_API_NER_BASE'] #NER endpoint\n",
    "# API_URL = \"https://n9mjb8bgycgo2pbs.us-east-1.aws.endpoints.huggingface.cloud\" #NER endpoint\n",
    "# text = \"My name is Andrew, I'm building DeepLearningAI and I live in California\"\n",
    "# get_completion(text, parameters=None, ENDPOINT_URL= API_URL)\n",
    "# # get_completion(text, parameters=None, ENDPOINT_URL= \"https://n9mjb8bgycgo2pbs.us-east-1.aws.endpoints.huggingface.cloud\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5f60b3-bdf0-4b96-a387-7a48b9017ca7",
   "metadata": {
    "id": "bd5f60b3-bdf0-4b96-a387-7a48b9017ca7"
   },
   "source": [
    "#### gr.interface()\n",
    "- Notice below that we pass in a list `[]` to `inputs` and to `outputs` because the function `fn` (in this case, `ner()`, can take in more than one input and return more than one output.\n",
    "- The number of objects passed to `inputs` list should match the number of parameters that the `fn` function takes in, and the number of objects passed to the `outputs` list should match the number of objects returned by the `fn` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e5c21254-128d-446c-b6dd-e30af26d436d",
   "metadata": {
    "height": 266,
    "id": "e5c21254-128d-446c-b6dd-e30af26d436d"
   },
   "outputs": [],
   "source": [
    "# not in use\n",
    "# def ner(input):\n",
    "#     output = get_completion(input, parameters=None, ENDPOINT_URL=API_URL)\n",
    "#     return {\"text\": input, \"entities\": output}\n",
    "\n",
    "# gr.close_all()\n",
    "# demo = gr.Interface(fn=ner,\n",
    "#                     inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "#                     outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "#                     title=\"NER with dslim/bert-base-NER\",\n",
    "#                     description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
    "#                     allow_flagging=\"never\",\n",
    "#                     #Here we introduce a new tag, examples, easy to use examples for your application\n",
    "#                     examples=[\"My name is Andrew and I live in California\", \"My name is Poli and work at HuggingFace\"])\n",
    "# demo.launch(share=True, server_port=int(8050))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f16ad4",
   "metadata": {
    "id": "60f16ad4"
   },
   "source": [
    "### Adding a helper function to merge tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4dc278e9-87b4-420b-89e9-7120dc4be754",
   "metadata": {
    "height": 538,
    "id": "4dc278e9-87b4-420b-89e9-7120dc4be754"
   },
   "outputs": [],
   "source": [
    "# not in use\n",
    "# def merge_tokens(tokens):\n",
    "#     merged_tokens = []\n",
    "#     for token in tokens:\n",
    "#         if merged_tokens and token['entity'].startswith('I-') and merged_tokens[-1]['entity'].endswith(token['entity'][2:]):\n",
    "#             # If current token continues the entity of the last one, merge them\n",
    "#             last_token = merged_tokens[-1]\n",
    "#             last_token['word'] += token['word'].replace('##', '')\n",
    "#             last_token['end'] = token['end']\n",
    "#             last_token['score'] = (last_token['score'] + token['score']) / 2\n",
    "#         else:\n",
    "#             # Otherwise, add the token to the list\n",
    "#             merged_tokens.append(token)\n",
    "\n",
    "#     return merged_tokens\n",
    "\n",
    "# def ner(input):\n",
    "#     output = get_completion(input, parameters=None, ENDPOINT_URL=API_URL)\n",
    "#     merged_tokens = merge_tokens(output)\n",
    "#     return {\"text\": input, \"entities\": merged_tokens}\n",
    "\n",
    "# gr.close_all()\n",
    "# demo = gr.Interface(fn=ner,\n",
    "#                     inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "#                     outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "#                     title=\"NER with dslim/bert-base-NER\",\n",
    "#                     description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
    "#                     allow_flagging=\"never\",\n",
    "#                     examples=[\"My name is Andrew, I'm building DeeplearningAI and I live in California\", \"My name is Poli, I live in Vienna and work at HuggingFace\"])\n",
    "\n",
    "# demo.launch(share=True, server_port=int(8040))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3cccdb9b-0c3a-406e-95bc-106705aeb010",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "3cccdb9b-0c3a-406e-95bc-106705aeb010",
    "outputId": "eba5c8a4-3aaf-47b8-b550-a2ae9b0f72b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 8040\n",
      "Closing server running on port: 8060\n",
      "Closing server running on port: 8050\n",
      "Closing server running on port: 8060\n",
      "Closing server running on port: 8070\n",
      "Closing server running on port: 8050\n",
      "Closing server running on port: 8070\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac5cd66-b6c2-4a01-a06a-44ba0c4c7394",
   "metadata": {
    "id": "cac5cd66-b6c2-4a01-a06a-44ba0c4c7394"
   },
   "source": [
    "## How to get your own Hugging Face API key (token)\n",
    "\n",
    "Hugging Face \"API keys\" are called \"User Access tokens\".  \n",
    "\n",
    "You can create your own User Access Tokens here: [Access Tokens](https://huggingface.co/settings/tokens).\n",
    "\n",
    "#### Save your user access tokens to environment variables\n",
    "To save your access token securely on your own machine:\n",
    "- Create a `.env` file in the root directory of your project.\n",
    "- Edit the file to contain the following:  \n",
    "`HF_API_KEY=\"abc123\"` replace that string with your user access token.\n",
    "- Save the .env file.\n",
    "- Install Python-dotenv, which allows you to run that first code cell at the top of this jupyter notebook:  \n",
    "`pip install python-dotenv`\n",
    "\n",
    "\n",
    "For more information on how to get your own access tokens, please see [User access tokens](https://huggingface.co/docs/hub/security-tokens#:~:text=To%20create%20an%20access%20token,you're%20ready%20to%20go!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a5a409",
   "metadata": {
    "height": 30,
    "id": "f7a5a409"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
